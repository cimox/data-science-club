{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict risk of running out of stock\n",
    "Product backorder - running out of stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data\n",
    "Load data from csv and show first rows.\n",
    "\n",
    "Features:\n",
    "- sku - Random ID for the product\n",
    "- national_inv - Current inventory level for the part\n",
    "- lead_time - Transit time for product (if available)\n",
    "- in_transit_qty - Amount of product in transit from source\n",
    "- forecast_3_month - Forecast sales for the next 3 months\n",
    "- forecast_6_month - Forecast sales for the next 6 months\n",
    "- forecast_9_month - Forecast sales for the next 9 months\n",
    "- sales_1_month - Sales quantity for the prior 1 month time period\n",
    "- sales_3_month - Sales quantity for the prior 3 month time period\n",
    "- sales_6_month - Sales quantity for the prior 6 month time period\n",
    "- sales_9_month - Sales quantity for the prior 9 month time period\n",
    "- min_bank - Minimum recommend amount to stock\n",
    "- potential_issue - Source issue for part identified\n",
    "- pieces_past_due - Parts overdue from source\n",
    "- perf_6_month_avg - Source performance for prior 6 month period\n",
    "- perf_12_month_avg - Source performance for prior 12 month period\n",
    "- local_bo_qty - Amount of stock orders overdue\n",
    "- deck_risk - Part risk flag\n",
    "- oe_constraint - Part risk flag\n",
    "- ppap_risk - Part risk flag\n",
    "- stop_auto_buy - Part risk flag\n",
    "- rev_stop - Part risk flag\n",
    "- **went_on_backorder** - Product actually went on backorder. This is the target value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Kaggle_Training_Dataset_v2.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "- Task 1: Deal with NaN data and useless features (e.g. sku - random id of the product).\n",
    "- Task 2: What to do with textual data?\n",
    "- Task 3: Data normalization. In general, learning algorithms benefit from standardization of the data set - e.g. presence of outliers or different scales. http://scikit-learn.org/stable/modules/preprocessing.html#scaling-features-to-a-range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = sns.countplot(df.went_on_backorder)\n",
    "plot.set_title(\"Backorder distribtion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO we can try to balance data by undersampling, oversampling or weighting\n",
    "# hint: weighting by parameter class_weight in scikit-learn or http://contrib.scikit-learn.org/imbalanced-learn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building model\n",
    "\\#1 Split dataset to train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size = 0.3, random_state=42)\n",
    "X_train, y_train = train.drop('went_on_backorder', axis=1), train.went_on_backorder\n",
    "X_test, y_test= test.drop('went_on_backorder', axis=1), test.went_on_backorder\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\#2 Train classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "# TODO explore model parameters, either manually or by grid searching\n",
    "# TODO try to train more powerful classification algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics for each class: precision, recall, f1-score and support. \n",
    "\n",
    "https://en.wikipedia.org/wiki/Precision_and_recall#Definition_.28classification_context.29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = classifier.predict_proba(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba[:,0])\n",
    "auc_score = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(tpr, fpr, 'b-')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlabel('True Positive Rate')\n",
    "plt.ylabel('False Positive Rate')\n",
    "plt.title('AUC : {}'.format(auc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which features are the most important for the classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_importances(coef, names):\n",
    "    imp = coef\n",
    "    imp,names = zip(*sorted(zip(imp,names)))\n",
    "    plt.barh(range(len(names)), imp, align='center')\n",
    "    plt.yticks(range(len(names)), names)\n",
    "    plt.show()\n",
    "features_importances(classifier.feature_importances_, train.drop('went_on_backorder', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
